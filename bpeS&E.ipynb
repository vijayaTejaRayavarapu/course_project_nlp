{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bpemb import BPEmb\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.init import xavier_uniform_\n",
    "import copy\n",
    "from typing import Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "bpemb_sa = BPEmb(lang=\"sa\", vs=100000,dim=300,add_pad_emb=True)\n",
    "reg = re.compile(\"[!@#$%^&*,/\\_-`~\\n]\")\n",
    "sansList = []\n",
    "with open('allData.csv', encoding = \"utf-8\") as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for i in spamreader:\n",
    "        if i != \"SANS\":\n",
    "            sansList.append(bpemb_sa.encode(reg.sub(\" \",i[1][7:][:-4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bpemb_sa = BPEmb(lang=\"sa\", vs=100000,dim=300,add_pad_emb=True)\n",
    "# encodedSansList = []\n",
    "# for i in sansList:\n",
    "#     encodedSansList.append(autograd.Variable(torch.tensor([[bpemb_sa.encode_ids(i)]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rege = re.compile(\"[!@#$%^&*:,/\\_`~\\n]\")\n",
    "engList = []\n",
    "bpemb_en = BPEmb(lang=\"en\", vs=100000,dim=300, add_pad_emb= True)\n",
    "with open('allData.csv', encoding = \"utf-8\") as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for i in spamreader:\n",
    "        if i != \"ENG\":\n",
    "            engList.append(bpemb_en.encode(rege.sub(\" \",i[2][7:][:-4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sans_train, sans_test, eng_train, eng_test = train_test_split(sansList,engList,test_size=0.20,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14640"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = {}\n",
    "for each in eng_train:\n",
    "    for i in each:\n",
    "        if i not in eng_vocab.keys():\n",
    "            eng_vocab[i] = len(eng_vocab) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sans_vocab = {}\n",
    "for each in sans_train:\n",
    "    for i in each:\n",
    "        if i not in sans_vocab.keys():\n",
    "            sans_vocab[i] = len(sans_vocab) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_len, tgt_vocab_len = len(sans_vocab), len(eng_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sans_vocab[\"<pad>\"] = 0\n",
    "eng_vocab[\"<pad>\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bpemb_en = BPEmb(lang=\"en\", vs=100000,dim=300, add_pad_emb= True)\n",
    "# encodedEngList = []\n",
    "# for i in engList:\n",
    "#     encodedEngList.append(autograd.Variable(torch.tensor([[bpemb_en.encode_ids(i)]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21827 17999\n"
     ]
    }
   ],
   "source": [
    "eng_vocab[\"<bos>\"] = 1\n",
    "eng_vocab[\"<eos>\"] = 2\n",
    "src_vocab_len, tgt_vocab_len = len(sans_vocab), len(eng_vocab)\n",
    "print(src_vocab_len, tgt_vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "entireSansTensorList = []\n",
    "for i in range(0, len(sans_train), batch_size):\n",
    "    temp1 = []\n",
    "    longest = len(max(sans_train[i:i+batch_size], key=len))\n",
    "    #print(longest)\n",
    "    for a in sans_train[i:i+batch_size]:\n",
    "        temp2 = []\n",
    "        for e in a:  \n",
    "            temp2.append(sans_vocab.get(e))\n",
    "        zeros = [0] * (longest - len(a))\n",
    "        temp1.append(temp2 + zeros)\n",
    "    entireSansTensorList.append(autograd.Variable(torch.tensor(temp1)).transpose(0,1).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([89, 240])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entireSansTensorList[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "entireEngTensorList = []\n",
    "for i in range(0, len(eng_train), batch_size):\n",
    "    temp1 = []\n",
    "    longest = len(max(eng_train[i:i+batch_size], key=len))\n",
    "#     print(longest)\n",
    "    for a in eng_train[i:i+batch_size]:\n",
    "        temp2 = []\n",
    "        for e in a:  \n",
    "            temp2.append(eng_vocab.get(e))\n",
    "        zeros = [0] * (longest - len(a))\n",
    "        temp1.append([1] + temp2 + [2] + zeros)\n",
    "    entireEngTensorList.append(autograd.Variable(torch.tensor(temp1)).transpose(0,1).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entireEngTensorList[0].size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self, d_model: int = 512, nhead: int = 8, num_encoder_layers: int = 6,\n",
    "                 num_decoder_layers: int = 6, dim_feedforward: int = 2048, dropout: float = 0.1,\n",
    "                 activation: str = \"relu\",source_vocab_length: int = 60000,target_vocab_length: int = 60000) -> None:\n",
    "        super(MyTransformer, self).__init__()\n",
    "        self.source_embedding = nn.Embedding(source_vocab_length, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        encoder_norm = nn.LayerNorm(d_model)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)\n",
    "        self.target_embedding = nn.Embedding(target_vocab_length, d_model)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        decoder_norm = nn.LayerNorm(d_model)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm)\n",
    "        self.out = nn.Linear(512, target_vocab_length)\n",
    "        self._reset_parameters()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "\n",
    "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Optional[Tensor] = None, tgt_mask: Optional[Tensor] = None,\n",
    "                memory_mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None,\n",
    "                tgt_key_padding_mask: Optional[Tensor] = None, memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
    "        if src.size(1) != tgt.size(1):\n",
    "            raise RuntimeError(\"the batch number of src and tgt must be equal\")\n",
    "        src = self.source_embedding(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        tgt = self.target_embedding(tgt)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
    "                              tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                              memory_key_padding_mask=memory_key_padding_mask)\n",
    "        output = self.out(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        r\"\"\"Initiate parameters in the transformer model.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyTransformer(source_vocab_length=src_vocab_len,target_vocab_length=src_vocab_len)\n",
    "model = model\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "#optim = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sans_train, eng_train, sans_test, eng_test, model, optim, num_epochs,use_gpu=False): \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        # Train model\n",
    "        model.train()\n",
    "        for i in range(len(sans_train)):\n",
    "            #m = torch.zeros(1,1,512-(sans_train[i].size(2)))\n",
    "            #print(i)\n",
    "            src = sans_train[i]\n",
    "            #src = torch.cat((sans_train[i],m),2).long()\n",
    "            #n = torch.zeros(1, 1, 512 - (eng_train[i].size(2))-2)\n",
    "            trg = eng_train[i]\n",
    "            #trg = torch.cat((eng_new,n),2).long()\n",
    "#             print(src.size(), trg.size())\n",
    "            #change to shape (bs , max_seq_len)\n",
    "            src = src.transpose(0,1)\n",
    "            #change to shape (bs , max_seq_len+1) , Since right shifted\n",
    "            trg = trg.transpose(0,1)\n",
    "            trg_input = trg[:, :-1]\n",
    "            targets = trg[:, 1:].contiguous().view(-1)\n",
    "            src_mask = (src != 0)\n",
    "            src_mask = src_mask.float().masked_fill(src_mask == 0, float('-inf')).masked_fill(src_mask == 1, float(0.0))\n",
    "            src_mask = src_mask.cuda() if use_gpu else src_mask\n",
    "            trg_mask = (trg_input != 0)\n",
    "            trg_mask = trg_mask.float().masked_fill(trg_mask == 0, float('-inf')).masked_fill(trg_mask == 1, float(0.0))\n",
    "            trg_mask = trg_mask.cuda() if use_gpu else trg_mask\n",
    "            size = trg_input.size(1)\n",
    "            #print(size)\n",
    "            np_mask = torch.triu(torch.ones(size, size)==1).transpose(0,1)\n",
    "            np_mask = np_mask.float().masked_fill(np_mask == 0, float('-inf')).masked_fill(np_mask == 1, float(0.0))\n",
    "            np_mask = np_mask.cuda() if use_gpu else np_mask   \n",
    "            # Forward, backprop, optimizer\n",
    "            optim.zero_grad()\n",
    "            preds = model(src.transpose(0,1), trg_input.transpose(0,1))#, src_mask = src_mask)#, tgt_key_padding_mask=trg_mask)\n",
    "            preds = preds.transpose(0,1).contiguous().view(-1, preds.size(-1))\n",
    "            loss = F.cross_entropy(preds.to('cuda'),targets.to('cuda'), ignore_index=0,reduction='sum')\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_loss += loss.item()/src.size(1)\n",
    "            print(\"----------- Batch: \" + str(i) + \" loss: \" + str(train_loss))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(sans_test)):\n",
    "                src = sans_test[i]\n",
    "                #src = torch.cat((sans_train[i],m),2).long()\n",
    "                #n = torch.zeros(1, 1, 512 - (eng_train[i].size(2))-2)\n",
    "                trg = eng_test[i]\n",
    "                src = src.transpose(0,1)\n",
    "                #change to shape (bs , max_seq_len+1) , Since right shifted\n",
    "                trg = trg.transpose(0,1)\n",
    "                trg_input = trg[:, :-1]\n",
    "                targets = trg[:, 1:].contiguous().view(-1)\n",
    "                src_mask = (src != 0)\n",
    "                src_mask = src_mask.float().masked_fill(src_mask == 0, float('-inf')).masked_fill(src_mask == 1, float(0.0))\n",
    "                src_mask = src_mask.cuda() if use_gpu else src_mask\n",
    "                trg_mask = (trg_input != 0)\n",
    "                trg_mask = trg_mask.float().masked_fill(trg_mask == 0, float('-inf')).masked_fill(trg_mask == 1, float(0.0))\n",
    "                trg_mask = trg_mask.cuda() if use_gpu else trg_mask\n",
    "                size = trg_input.size(1)\n",
    "                #print(size)\n",
    "                np_mask = torch.triu(torch.ones(size, size)==1).transpose(0,1)\n",
    "                np_mask = np_mask.float().masked_fill(np_mask == 0, float('-inf')).masked_fill(np_mask == 1, float(0.0))\n",
    "                np_mask = np_mask.cuda() if use_gpu else np_mask\n",
    "\n",
    "                preds = model(src.transpose(0,1).to('cuda'), trg_input.transpose(0,1).to('cuda'), tgt_mask = np_mask)#, src_mask = src_mask)#, tgt_key_padding_mask=trg_mask)\n",
    "                preds = preds.transpose(0,1).contiguous().view(-1, preds.size(-1))         \n",
    "                loss = F.cross_entropy(preds.to('cuda'),targets.to('cuda'), ignore_index=0,reduction='sum')\n",
    "                valid_loss += loss.item()/src.size(1)\n",
    "            \n",
    "        # Log after each epoch\n",
    "        print(f'''Epoch [{epoch+1}/{num_epochs}] complete. Train Loss: {train_loss/src.size(1):.3f}. Val Loss: {valid_loss/src.size(1):.3f}''')\n",
    "        \n",
    "        #Save best model till now:\n",
    "        if valid_loss/len(sans_test)<min(valid_losses,default=1e9): \n",
    "            print(\"saving state dict\")\n",
    "            torch.save(model.state_dict(), f\"checkpoint_best_epoch.pt\")\n",
    "        \n",
    "        train_losses.append(train_loss/src.size(1))\n",
    "        valid_losses.append(valid_loss/src.size(1))\n",
    "        \n",
    "#         # Check Example after each epoch:\n",
    "# #         sentences = [\"This is an example to check how our model is performing.\"]\n",
    "# #         for sentence in sentences:\n",
    "# #             print(f\"Original Sentence: {sentence}\")\n",
    "# #             print(f\"Translated Sentence: {greeedy_decode_sentence(model,sentence)}\")\n",
    "    return train_losses,valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Batch: 0 loss: 842.8125\n",
      "----------- Batch: 1 loss: 1851.9152036516853\n",
      "----------- Batch: 2 loss: 2430.0981777896163\n"
     ]
    }
   ],
   "source": [
    "train_losses,valid_losses = train(entireSansTensorList, entireEngTensorList, entireSansTensorList, entireEngTensorList, model, optim, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
