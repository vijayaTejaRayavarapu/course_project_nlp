{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bpemb import BPEmb\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.init import xavier_uniform_\n",
    "import copy\n",
    "from typing import Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "bpemb_sa = BPEmb(lang=\"sa\", vs=100000,dim=300,add_pad_emb=True)\n",
    "reg = re.compile(\"[!@#$%^&*,/\\_-`~\\n]\")\n",
    "sansList = []\n",
    "with open('allData.csv', encoding = \"utf-8\") as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for i in spamreader:\n",
    "        if i != \"SANS\":\n",
    "            sansList.append(bpemb_sa.encode(reg.sub(\" \",i[1][7:][:-4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sansList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bpemb_sa = BPEmb(lang=\"sa\", vs=100000,dim=300,add_pad_emb=True)\n",
    "# encodedSansList = []\n",
    "# for i in sansList:\n",
    "#     encodedSansList.append(autograd.Variable(torch.tensor([[bpemb_sa.encode_ids(i)]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rege = re.compile(\"[!@#$%^&*:,/\\_`~\\n]\")\n",
    "engList = []\n",
    "bpemb_en = BPEmb(lang=\"en\", vs=100000,dim=300, add_pad_emb= True)\n",
    "with open('allData.csv', encoding = \"utf-8\") as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for i in spamreader:\n",
    "        if i != \"ENG\":\n",
    "            engList.append(bpemb_en.encode(rege.sub(\" \",i[2][7:][:-4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sans_train, sans_test, eng_train, eng_test = train_test_split(sansList,engList,test_size=0.20,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14640"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = {}\n",
    "for each in eng_train:\n",
    "    for i in each:\n",
    "        if i not in eng_vocab.keys():\n",
    "            eng_vocab[i] = len(eng_vocab) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sans_vocab = {}\n",
    "for each in sans_train:\n",
    "    for i in each:\n",
    "        if i not in sans_vocab.keys():\n",
    "            sans_vocab[i] = len(sans_vocab) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_len, tgt_vocab_len = len(sans_vocab), len(eng_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sans_vocab[\"<pad>\"] = 0\n",
    "eng_vocab[\"<pad>\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bpemb_en = BPEmb(lang=\"en\", vs=100000,dim=300, add_pad_emb= True)\n",
    "# encodedEngList = []\n",
    "# for i in engList:\n",
    "#     encodedEngList.append(autograd.Variable(torch.tensor([[bpemb_en.encode_ids(i)]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21828 18000\n"
     ]
    }
   ],
   "source": [
    "eng_vocab[\"<bos>\"] = 1\n",
    "eng_vocab[\"<eos>\"] = 2\n",
    "sans_vocab[\"<unk>\"] = 1\n",
    "eng_vocab[\"<unk>\"] = 3\n",
    "src_vocab_len, tgt_vocab_len = len(sans_vocab), len(eng_vocab)\n",
    "print(src_vocab_len, tgt_vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ñÅobserving'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(eng_vocab.keys())[list(eng_vocab.values()).index(1345)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "batch_size_test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "entireSansTensorList = []\n",
    "for i in range(0, len(sans_train), batch_size):\n",
    "    temp1 = []\n",
    "    longest = len(max(sans_train[i:i+batch_size], key=len))\n",
    "    #print(longest)\n",
    "    for a in sans_train[i:i+batch_size]:\n",
    "        temp2 = []\n",
    "        for e in a:  \n",
    "            temp2.append(sans_vocab.get(e))\n",
    "        zeros = [0] * (longest - len(a))\n",
    "        temp1.append(temp2 + zeros)\n",
    "    entireSansTensorList.append(autograd.Variable(torch.tensor(temp1)).transpose(0,1).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "entireSansTestTensorList = []\n",
    "for i in range(0, len(sans_test), batch_size_test):\n",
    "    temp1 = []\n",
    "    longest = len(max(sans_test[i:i+batch_size_test], key=len))\n",
    "    #print(longest)\n",
    "    for a in sans_test[i:i+batch_size_test]:\n",
    "        temp2 = []\n",
    "        for e in a:  \n",
    "            temp2.append(sans_vocab.get(e,1))\n",
    "        zeros = [0] * (longest - len(a))\n",
    "        temp1.append(temp2 + zeros)\n",
    "    entireSansTestTensorList.append(autograd.Variable(torch.tensor(temp1)).transpose(0,1).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entireSansTensorList[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "entireEngTensorList = []\n",
    "for i in range(0, len(eng_train), batch_size):\n",
    "    temp1 = []\n",
    "    longest = len(max(eng_train[i:i+batch_size], key=len))\n",
    "#     print(longest)\n",
    "    for a in eng_train[i:i+batch_size]:\n",
    "        temp2 = []\n",
    "        for e in a:  \n",
    "            temp2.append(eng_vocab.get(e))\n",
    "        zeros = [0] * (longest - len(a))\n",
    "        temp1.append([1] + temp2 + [2] + zeros)\n",
    "    entireEngTensorList.append(autograd.Variable(torch.tensor(temp1)).transpose(0,1).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "entireEngTestTensorList = []\n",
    "for i in range(0, len(eng_test), batch_size_test):\n",
    "    temp1 = []\n",
    "    longest = len(max(eng_test[i:i+batch_size_test], key=len))\n",
    "#     print(longest)\n",
    "    for a in eng_test[i:i+batch_size_test]:\n",
    "        temp2 = []\n",
    "        for e in a:  \n",
    "            temp2.append(eng_vocab.get(e,3))\n",
    "        zeros = [0] * (longest - len(a))\n",
    "        temp1.append([1] + temp2 + [2] + zeros)\n",
    "    entireEngTestTensorList.append(autograd.Variable(torch.tensor(temp1)).transpose(0,1).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "src = entireEngTensorList[0].transpose(0,1)\n",
    "print(src.size(1))\n",
    "#src_mask = src_mask.float().masked_fill(src_mask == 0, float('-inf')).masked_fill(src_mask == 1, float(0.0))\n",
    "#print(src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sans_train_tensor, sans_val_tensor, eng_train_tensor, eng_val_tensor = train_test_split(entireSansTensorList,entireEngTensorList,test_size=0.10,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self, d_model: int = 512, nhead: int = 8, num_encoder_layers: int = 6,\n",
    "                 num_decoder_layers: int = 6, dim_feedforward: int = 2048, dropout: float = 0.1,\n",
    "                 activation: str = \"relu\",source_vocab_length: int = 60000,target_vocab_length: int = 60000) -> None:\n",
    "        super(MyTransformer, self).__init__()\n",
    "        self.source_embedding = nn.Embedding(source_vocab_length, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        encoder_norm = nn.LayerNorm(d_model)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)\n",
    "        self.target_embedding = nn.Embedding(target_vocab_length, d_model)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        decoder_norm = nn.LayerNorm(d_model)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm)\n",
    "        self.out = nn.Linear(512, target_vocab_length)\n",
    "        self._reset_parameters()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "\n",
    "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Optional[Tensor] = None, tgt_mask: Optional[Tensor] = None,\n",
    "                memory_mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None,\n",
    "                tgt_key_padding_mask: Optional[Tensor] = None, memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
    "        if src.size(1) != tgt.size(1):\n",
    "            raise RuntimeError(\"the batch number of src and tgt must be equal\")\n",
    "        src = self.source_embedding(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        tgt = self.target_embedding(tgt)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
    "                              tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                              memory_key_padding_mask=memory_key_padding_mask)\n",
    "        output = self.out(output)\n",
    "        return output\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        r\"\"\"Initiate parameters in the transformer model.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyTransformer(source_vocab_length=src_vocab_len,target_vocab_length=src_vocab_len)\n",
    "model = model.to(\"cuda\")\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=0.0000251, betas=(0.9, 0.98), eps=1e-9)\n",
    "#optim = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sans_train, eng_train, sans_test, eng_test, model, optim, num_epochs,use_gpu=True): \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        # Train model\n",
    "        model.train()\n",
    "        for i in range(len(sans_train)):\n",
    "            #m = torch.zeros(1,1,512-(sans_train[i].size(2)))\n",
    "            #print(i)\n",
    "            src = sans_train[i]\n",
    "            #src = torch.cat((sans_train[i],m),2).long()\n",
    "            #n = torch.zeros(1, 1, 512 - (eng_train[i].size(2))-2)\n",
    "            trg = eng_train[i]\n",
    "            #trg = torch.cat((eng_new,n),2).long()\n",
    "#             print(src.size(), trg.size())\n",
    "            #change to shape (bs , max_seq_len)\n",
    "            src = src.transpose(0,1)\n",
    "            #change to shape (bs , max_seq_len+1) , Since right shifted\n",
    "            trg = trg.transpose(0,1)\n",
    "            trg_input = trg[:, :-1]\n",
    "            targets = trg[:, 1:].contiguous().view(-1)\n",
    "            src_pad_mask = (src == 0)\n",
    "            src_size = src.size(1)\n",
    "            src_mask = (torch.triu(torch.ones(src_size, src_size)) == 1).transpose(0, 1)\n",
    "            src_mask = src_mask.float().masked_fill(src_mask == 0, float('-inf')).masked_fill(src_mask == 1, float(0.0))\n",
    "            src_mask = src_mask.cuda() if use_gpu else src_mask\n",
    "            src_pad_mask = src_pad_mask.cuda() if use_gpu else src_pad_mask\n",
    "            trg_pad_mask = (trg_input == 0)\n",
    "            trg_pad_mask = trg_pad_mask.cuda() if use_gpu else trg_pad_mask\n",
    "            size = trg_input.size(1)\n",
    "            mem_mask = (torch.triu(torch.ones(src.size(1), size)) == 1).transpose(0, 1)\n",
    "            mem_mask = mem_mask.float().masked_fill(mem_mask == 0, float('-inf')).masked_fill(mem_mask == 1, float(0.0))\n",
    "            mem_mask = mem_mask.cuda()\n",
    "            np_mask = torch.triu(torch.ones(size, size)==1).transpose(0,1)\n",
    "            np_mask = np_mask.float().masked_fill(np_mask == 0, float('-inf')).masked_fill(np_mask == 1, float(0.0))\n",
    "            np_mask = np_mask.cuda() if use_gpu else np_mask   \n",
    "            # Forward, backprop, optimizer\n",
    "            optim.zero_grad()\n",
    "            preds = model(src.transpose(0,1).to(\"cuda\"), trg_input.transpose(0,1).to(\"cuda\"), src_key_padding_mask = src_pad_mask, tgt_key_padding_mask=trg_pad_mask, memory_key_padding_mask = src_pad_mask, src_mask = src_mask, tgt_mask = np_mask, memory_mask = mem_mask)\n",
    "            #print(preds)\n",
    "            preds = preds.transpose(0,1).contiguous().view(-1, preds.size(-1))\n",
    "            loss = F.cross_entropy(preds.to('cuda'),targets.to('cuda'), ignore_index=0,reduction='sum')\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_loss += loss.item()/src.size(1)\n",
    "            print(\"----------- Batch: \" + str(i) + \" loss: \" + str(train_loss))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(sans_test)):\n",
    "                src = sans_test[i]\n",
    "                #src = torch.cat((sans_train[i],m),2).long()\n",
    "                #n = torch.zeros(1, 1, 512 - (eng_train[i].size(2))-2)\n",
    "                trg = eng_test[i]\n",
    "                #src = src.transpose(0,1)\n",
    "                #change to shape (bs , max_seq_len+1) , Since right shifted\n",
    "                #trg = trg.transpose(0,1)\n",
    "                trg_input = trg[:, :-1]\n",
    "                targets = trg[:, 1:].contiguous().view(-1)\n",
    "                src_pad_mask = (src == 0)\n",
    "                src_size = src.size(1)\n",
    "                src_mask = (torch.triu(torch.ones(src_size, src_size)) == 1).transpose(0, 1)\n",
    "                src_mask = src_mask.float().masked_fill(src_mask == 0, float('-inf')).masked_fill(src_mask == 1, float(0.0))\n",
    "                src_mask = src_mask.cuda() if use_gpu else src_mask\n",
    "                src_pad_mask = src_pad_mask.cuda() if use_gpu else src_pad_mask\n",
    "                trg_pad_mask = (trg_input == 0)\n",
    "                trg_pad_mask = trg_pad_mask.cuda() if use_gpu else trg_pad_mask\n",
    "                size = trg_input.size(1)\n",
    "                mem_mask = (torch.triu(torch.ones(src.size(1), size)) == 1).transpose(0, 1)\n",
    "                mem_mask = mem_mask.float().masked_fill(mem_mask == 0, float('-inf')).masked_fill(mem_mask == 1, float(0.0))\n",
    "                mem_mask = mem_mask.cuda()\n",
    "                np_mask = torch.triu(torch.ones(size, size)==1).transpose(0,1)\n",
    "                np_mask = np_mask.float().masked_fill(np_mask == 0, float('-inf')).masked_fill(np_mask == 1, float(0.0))\n",
    "                np_mask = np_mask.cuda() if use_gpu else np_mask\n",
    "\n",
    "                preds = model(src.transpose(0,1).to('cuda'), trg_input.transpose(0,1).to('cuda'), src_key_padding_mask = src_pad_mask, tgt_key_padding_mask=trg_pad_mask, memory_key_padding_mask = src_pad_mask, src_mask = src_mask, tgt_mask = np_mask, memory_mask = mem_mask)\n",
    "                preds = preds.transpose(0,1).contiguous().view(-1, preds.size(-1))         \n",
    "                loss = F.cross_entropy(preds.to('cuda'),targets.to('cuda'), ignore_index=0,reduction='sum')\n",
    "                valid_loss += loss.item()/src.size(1)\n",
    "            \n",
    "        # Log after each epoch\n",
    "        print(f'''Epoch [{epoch+1}/{num_epochs}] complete. Train Loss: {train_loss/len(sans_train):.3f}. Val Loss: {valid_loss/len(sans_test):.3f}''')\n",
    "        \n",
    "        #Save best model till now:\n",
    "        if valid_loss/len(sans_test)<min(valid_losses,default=1e9): \n",
    "            print(\"saving state dict\")\n",
    "            torch.save(model.state_dict(), f\"checkpoint_best_epoch.pt\")\n",
    "        \n",
    "        train_losses.append(train_loss/len(sans_train))\n",
    "        valid_losses.append(valid_loss/len(sans_test))\n",
    "        \n",
    "#         # Check Example after each epoch:\n",
    "# #         sentences = [\"This is an example to check how our model is performing.\"]\n",
    "# #         for sentence in sentences:\n",
    "# #             print(f\"Original Sentence: {sentence}\")\n",
    "# #             print(f\"Translated Sentence: {greeedy_decode_sentence(model,sentence)}\")\n",
    "    return train_losses,valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Batch: 0 loss: 29.46626683285362\n",
      "----------- Batch: 1 loss: 71.62312718441612\n",
      "----------- Batch: 2 loss: 102.10975266017734\n",
      "----------- Batch: 3 loss: 125.64339659463914\n",
      "----------- Batch: 4 loss: 166.8838913863058\n",
      "----------- Batch: 5 loss: 199.9909241621847\n",
      "----------- Batch: 6 loss: 246.57531230821837\n",
      "----------- Batch: 7 loss: 274.25908139557635\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-7435eea2a95d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msans_train_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meng_train_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msans_val_tensor\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0meng_val_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-74-79c86ee6e81a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(sans_train, eng_train, sans_test, eng_test, model, optim, num_epochs, use_gpu)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses,valid_losses = train(sans_train_tensor, eng_train_tensor, sans_val_tensor ,eng_val_tensor, model, optim, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"after_10_epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decoder(pred):\n",
    "    vals = []\n",
    "    for i in range(len(pred)):\n",
    "        each = pred[i]\n",
    "        idxs = np.argmax(each, axis=1)\n",
    "        vals.append(list(eng_vocab.keys())[list(eng_vocab.values()).index(idxs[3])])\n",
    "    print(vals)\n",
    "    return bpemb_en.decode(vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model(sans_val_tensor[0].to('cuda'), eng_val_tensor[0].to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.size())\n",
    "print(len(eng_val_tensor[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoder(out.to('cpu').detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoder(out.to('cpu').detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoder(out.to('cpu').detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoder(out.to('cpu').detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
